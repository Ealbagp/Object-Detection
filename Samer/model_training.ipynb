{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import dataloader\n",
    "from tqdm import tqdm\n",
    "\n",
    "from model_architecture import Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROPOSAL_SIZE = (64, 64)\n",
    "\n",
    "dataset_train = dataloader.PotholeDataset('../Potholes/annotated-images/', '../Potholes/proposals/', '../Potholes/annotated-images/', proposals_per_batch=5, proposal_size=PROPOSAL_SIZE, split='train')\n",
    "dataset_val = dataloader.PotholeDataset('../Potholes/annotated-images/', '../Potholes/proposals/', '../Potholes/annotated-images/', proposals_per_batch=5, proposal_size=PROPOSAL_SIZE, split='val')\n",
    "dataset_test = dataloader.PotholeDataset('../Potholes/annotated-images/', '../Potholes/proposals/', '../Potholes/annotated-images/', proposals_per_batch=5, proposal_size=PROPOSAL_SIZE, split='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "        nn.init.xavier_uniform_(m.weight)\n",
    "\n",
    "model = Network()\n",
    "model.apply(init_weights)\n",
    "model.to(device)\n",
    "#Initialize the optimizer\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.00001, weight_decay=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, num_epochs=10):\n",
    "    def loss_fun(output, target):\n",
    "        return F.cross_entropy(output, target)\n",
    "    \n",
    "    out_dict = {\n",
    "              'train_acc': [],\n",
    "              'val_acc': [],\n",
    "              'train_loss': [],\n",
    "              'val_loss': []}\n",
    "  \n",
    "    for epoch in tqdm(range(num_epochs), unit='epoch'):\n",
    "        model.train()\n",
    "        train_correct = 0\n",
    "        train_loss = []\n",
    "        # for minibatch_no, (data, target) in tqdm(enumerate(dataset), total=len(dataset)):\n",
    "        for idx, (single_image_dict) in tqdm(enumerate(dataset_train), total=len(dataset_train)):\n",
    "            # print(single_image_dict['labels'])\n",
    "            # for proposal, label, proposal_image in zip(single_image_dict['proposals'], single_image_dict['labels'], single_image_dict['proposal_images']):\n",
    "            # print(label)\n",
    "            proposal_image, label = single_image_dict['proposal_images'].to(device), single_image_dict['labels'].to(device)\n",
    "            #Zero the gradients computed for each weight\n",
    "            optimizer.zero_grad()\n",
    "            #Forward pass your image through the network\n",
    "            output = model(proposal_image)\n",
    "            #Compute the loss\n",
    "\n",
    "            # print(f\"Proposal shape: {single_image_dict['proposals'].shape if single_image_dict['proposals'] is not None else 'None'}\")\n",
    "            # print(f\"Proposal image shape: {proposal_image.shape if proposal_image is not None else 'None'}\")\n",
    "            # print(f\"Label: {label}\")\n",
    "            # print(f\"Label shape: {label.shape if isinstance(label, torch.Tensor) else 'Not a Tensor'}\")\n",
    "\n",
    "            loss = loss_fun(output, label)\n",
    "            #Backward pass through the network\n",
    "            loss.backward()\n",
    "            #Update the weights\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss.append(loss.item())\n",
    "            #Compute how many were correctly classified\n",
    "            predicted = output.argmax(1)\n",
    "            train_correct += (label==predicted).sum().cpu().item()\n",
    "\n",
    "        #Comput the test accuracy\n",
    "        val_loss = []\n",
    "        val_correct = 0\n",
    "        model.eval()\n",
    "        for single_val_dict in dataset_val:\n",
    "            # for proposal_val, label_val, proposal_image_val in zip(single_val_dict['proposals'], single_val_dict['labels'], single_val_dict['proposal_images']):\n",
    "            proposal_image_val, label_val = single_val_dict['proposal_images'].to(device), single_val_dict['labels'].to(device)\n",
    "            with torch.no_grad():\n",
    "                output = model(proposal_image_val)\n",
    "\n",
    "            val_loss.append(loss_fun(output, label_val).cpu().item())\n",
    "            predicted = output.argmax(1)\n",
    "            val_correct += (label_val==predicted).sum().cpu().item()\n",
    "\n",
    "        out_dict['train_acc'].append(train_correct/len(dataset_train))\n",
    "        out_dict['val_acc'].append(val_correct/len(dataset_val))\n",
    "        out_dict['train_loss'].append(np.mean(train_loss))\n",
    "        out_dict['val_loss'].append(np.mean(val_loss))\n",
    "\n",
    "        print(f\"Loss train: {np.mean(train_loss):.3f}\\t test: {np.mean(val_loss):.3f}\\t\",\n",
    "              f\"Accuracy train: {out_dict['train_acc'][-1]*100/5:.1f}%\\t test: {out_dict['val_acc'][-1]*100/5:.1f}%\") # Dividing by 5 because of the batch_size\n",
    "        \n",
    "    return out_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?epoch/s]c:\\Users\\samer\\Documents\\Intro to deep learning for computer vision\\pothole_detector\\dataloader.py:153: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels = torch.tensor(labels[selected_indices])\n",
      "100%|██████████| 206/206 [00:08<00:00, 23.30it/s]\n",
      " 10%|█         | 1/10 [00:09<01:26,  9.59s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss train: 0.427\t test: 0.426\t Accuracy train: 90.3%\t test: 89.5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 206/206 [00:06<00:00, 29.61it/s]\n",
      " 20%|██        | 2/10 [00:17<01:07,  8.45s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss train: 0.423\t test: 0.440\t Accuracy train: 89.6%\t test: 87.7%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 206/206 [00:06<00:00, 30.00it/s]\n",
      " 30%|███       | 3/10 [00:24<00:56,  8.04s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss train: 0.397\t test: 0.448\t Accuracy train: 92.1%\t test: 86.8%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 206/206 [00:07<00:00, 29.38it/s]\n",
      " 40%|████      | 4/10 [00:32<00:47,  7.93s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss train: 0.413\t test: 0.399\t Accuracy train: 90.5%\t test: 91.8%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 206/206 [00:06<00:00, 29.73it/s]\n",
      " 50%|█████     | 5/10 [00:40<00:39,  7.82s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss train: 0.402\t test: 0.403\t Accuracy train: 91.6%\t test: 91.4%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 206/206 [00:06<00:00, 29.59it/s]\n",
      " 60%|██████    | 6/10 [00:47<00:31,  7.77s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss train: 0.422\t test: 0.402\t Accuracy train: 89.5%\t test: 91.4%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 206/206 [00:07<00:00, 29.38it/s]\n",
      " 70%|███████   | 7/10 [00:55<00:23,  7.75s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss train: 0.421\t test: 0.422\t Accuracy train: 89.6%\t test: 89.5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 206/206 [00:07<00:00, 29.20it/s]\n",
      " 80%|████████  | 8/10 [01:03<00:15,  7.77s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss train: 0.403\t test: 0.385\t Accuracy train: 91.5%\t test: 93.2%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 206/206 [00:07<00:00, 29.14it/s]\n",
      " 90%|█████████ | 9/10 [01:11<00:07,  7.77s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss train: 0.424\t test: 0.439\t Accuracy train: 89.3%\t test: 87.7%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 206/206 [00:06<00:00, 29.50it/s]\n",
      "100%|██████████| 10/10 [01:18<00:00,  7.88s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss train: 0.404\t test: 0.452\t Accuracy train: 91.4%\t test: 86.4%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train_acc': [4.514563106796117,\n",
       "  4.480582524271845,\n",
       "  4.606796116504855,\n",
       "  4.524271844660194,\n",
       "  4.577669902912621,\n",
       "  4.475728155339806,\n",
       "  4.480582524271845,\n",
       "  4.572815533980583,\n",
       "  4.466019417475728,\n",
       "  4.567961165048544],\n",
       " 'val_acc': [4.4772727272727275,\n",
       "  4.386363636363637,\n",
       "  4.340909090909091,\n",
       "  4.590909090909091,\n",
       "  4.568181818181818,\n",
       "  4.568181818181818,\n",
       "  4.4772727272727275,\n",
       "  4.659090909090909,\n",
       "  4.386363636363637,\n",
       "  4.318181818181818],\n",
       " 'train_loss': [0.42712912354075794,\n",
       "  0.423326759662443,\n",
       "  0.3966262838215504,\n",
       "  0.41252137706117725,\n",
       "  0.4015305144983588,\n",
       "  0.4218972374513311,\n",
       "  0.4206112866262788,\n",
       "  0.4031321796977404,\n",
       "  0.4239137090236238,\n",
       "  0.40367281726263105],\n",
       " 'val_loss': [0.42559423026713455,\n",
       "  0.43983467803760007,\n",
       "  0.4482715278863907,\n",
       "  0.3990793146870353,\n",
       "  0.40325781364332547,\n",
       "  0.4024789665233005,\n",
       "  0.4217609390616417,\n",
       "  0.38459455357356503,\n",
       "  0.4387066052718596,\n",
       "  0.4517950341105461]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train(model, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
