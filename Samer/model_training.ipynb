{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import dataloader\n",
    "from tqdm import tqdm\n",
    "\n",
    "from model_architecture import Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROPOSAL_SIZE = (64, 64)\n",
    "batch_size = 200\n",
    "\n",
    "dataset_train = dataloader.PotholeDataset('./Potholes/annotated-images/', './Potholes/proposals/', './Potholes/annotated-images/', proposals_per_batch=batch_size, proposal_size=PROPOSAL_SIZE, split='train')\n",
    "dataset_val = dataloader.PotholeDataset('./Potholes/annotated-images/', './Potholes/proposals/', './Potholes/annotated-images/', proposals_per_batch=batch_size, proposal_size=PROPOSAL_SIZE, split='val')\n",
    "dataset_test = dataloader.PotholeDataset('./Potholes/annotated-images/', './Potholes/proposals/', './Potholes/annotated-images/', proposals_per_batch=batch_size, proposal_size=PROPOSAL_SIZE, split='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "        nn.init.xavier_uniform_(m.weight)\n",
    "\n",
    "model = Network()\n",
    "model.apply(init_weights)\n",
    "model.to(device)\n",
    "#Initialize the optimizer\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.00001, weight_decay=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, num_epochs=10):\n",
    "    def loss_fun(output, target):\n",
    "        return F.cross_entropy(output, target)\n",
    "    \n",
    "    out_dict = {\n",
    "              'train_acc': [],\n",
    "              'val_acc': [],\n",
    "              'train_loss': [],\n",
    "              'val_loss': []}\n",
    "  \n",
    "    for epoch in tqdm(range(num_epochs), unit='epoch'):\n",
    "        model.train()\n",
    "        train_correct = 0\n",
    "        train_loss = []\n",
    "        # for minibatch_no, (data, target) in tqdm(enumerate(dataset), total=len(dataset)):\n",
    "        for idx, (single_image_dict) in tqdm(enumerate(dataset_train), total=len(dataset_train)):\n",
    "            # for proposal, label, proposal_image in zip(single_image_dict['proposals'], single_image_dict['labels'], single_image_dict['proposal_images']):\n",
    "            proposal_image, label = single_image_dict['proposal_images'].to(device), single_image_dict['labels'].to(device)\n",
    "            #Zero the gradients computed for each weight\n",
    "            optimizer.zero_grad()\n",
    "            #Forward pass your image through the network\n",
    "            output = model(proposal_image)\n",
    "            #Compute the loss\n",
    "\n",
    "            # print(f\"Proposal shape: {single_image_dict['proposals'].shape if single_image_dict['proposals'] is not None else 'None'}\")\n",
    "            # print(f\"Proposal image shape: {proposal_image.shape if proposal_image is not None else 'None'}\")\n",
    "            # print(f\"Label: {label}\")\n",
    "            # print(f\"Label shape: {label.shape if isinstance(label, torch.Tensor) else 'Not a Tensor'}\")\n",
    "\n",
    "            loss = loss_fun(output, label)\n",
    "            #Backward pass through the network\n",
    "            loss.backward()\n",
    "            #Update the weights\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss.append(loss.item())\n",
    "            #Compute how many were correctly classified\n",
    "            predicted = output.argmax(1)\n",
    "            train_correct += (label==predicted).sum().cpu().item()\n",
    "\n",
    "        #Comput the test accuracy\n",
    "        val_loss = []\n",
    "        val_correct = 0\n",
    "        model.eval()\n",
    "        for single_val_dict in dataset_val:\n",
    "            # for proposal_val, label_val, proposal_image_val in zip(single_val_dict['proposals'], single_val_dict['labels'], single_val_dict['proposal_images']):\n",
    "            proposal_image_val, label_val = single_val_dict['proposal_images'].to(device), single_val_dict['labels'].to(device)\n",
    "            with torch.no_grad():\n",
    "                output = model(proposal_image_val)\n",
    "\n",
    "            val_loss.append(loss_fun(output, label_val).cpu().item())\n",
    "            predicted = output.argmax(1)\n",
    "            val_correct += (label_val==predicted).sum().cpu().item()\n",
    "\n",
    "        out_dict['train_acc'].append(train_correct/len(dataset_train)/batch_size)\n",
    "        out_dict['val_acc'].append(val_correct/len(dataset_val)/batch_size)\n",
    "        out_dict['train_loss'].append(np.mean(train_loss))\n",
    "        out_dict['val_loss'].append(np.mean(val_loss))\n",
    "\n",
    "        print(f\"Loss train: {np.mean(train_loss):.3f}\\t test: {np.mean(val_loss):.3f}\\t\",\n",
    "              f\"Accuracy train: {out_dict['train_acc'][-1]*100:.1f}%\\t test: {out_dict['val_acc'][-1]*100:.1f}%\") # Dividing by 5 because of the batch_size\n",
    "        \n",
    "    return out_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?epoch/s]\n",
      "  0%|          | 0/206 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[Ac:\\Users\\samer\\Documents\\Intro to deep learning for computer vision\\pothole_detector\\dataloader.py:153: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels = torch.tensor(labels[selected_indices])\n",
      "100%|██████████| 206/206 [01:28<00:00,  2.32it/s]\n",
      " 10%|█         | 1/10 [01:37<14:35, 97.24s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss train: 0.437\t test: 0.415\t Accuracy train: 82.2%\t test: 82.8%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 206/206 [01:27<00:00,  2.36it/s]\n",
      " 20%|██        | 2/10 [03:13<12:52, 96.55s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss train: 0.419\t test: 0.414\t Accuracy train: 82.1%\t test: 82.6%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 206/206 [01:28<00:00,  2.34it/s]\n",
      " 30%|███       | 3/10 [04:50<11:17, 96.76s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss train: 0.416\t test: 0.409\t Accuracy train: 82.0%\t test: 82.9%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 206/206 [01:28<00:00,  2.32it/s]\n",
      " 40%|████      | 4/10 [06:28<09:43, 97.22s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss train: 0.414\t test: 0.410\t Accuracy train: 82.1%\t test: 82.7%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 206/206 [01:28<00:00,  2.32it/s]\n",
      " 50%|█████     | 5/10 [08:06<08:07, 97.55s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss train: 0.413\t test: 0.410\t Accuracy train: 82.2%\t test: 82.7%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 206/206 [01:33<00:00,  2.21it/s]\n",
      " 60%|██████    | 6/10 [09:50<06:38, 99.63s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss train: 0.415\t test: 0.411\t Accuracy train: 82.0%\t test: 82.6%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 206/206 [01:43<00:00,  1.99it/s]\n",
      " 70%|███████   | 7/10 [11:42<05:11, 103.98s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss train: 0.414\t test: 0.409\t Accuracy train: 82.0%\t test: 82.8%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 206/206 [01:36<00:00,  2.13it/s]\n",
      " 80%|████████  | 8/10 [13:29<03:29, 104.65s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss train: 0.413\t test: 0.410\t Accuracy train: 82.1%\t test: 82.7%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 206/206 [01:36<00:00,  2.14it/s]\n",
      " 90%|█████████ | 9/10 [15:14<01:44, 104.99s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss train: 0.413\t test: 0.410\t Accuracy train: 82.1%\t test: 82.7%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 206/206 [01:33<00:00,  2.20it/s]\n",
      "100%|██████████| 10/10 [16:57<00:00, 101.78s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss train: 0.413\t test: 0.409\t Accuracy train: 82.1%\t test: 82.8%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train_acc': [0.8215776699029127,\n",
       "  0.8210679611650485,\n",
       "  0.8200242718446602,\n",
       "  0.8211407766990291,\n",
       "  0.8216019417475728,\n",
       "  0.8196116504854369,\n",
       "  0.8202669902912622,\n",
       "  0.8209708737864078,\n",
       "  0.8209951456310679,\n",
       "  0.8210679611650485],\n",
       " 'val_acc': [0.8280681818181819,\n",
       "  0.8260227272727273,\n",
       "  0.8289772727272726,\n",
       "  0.8273863636363636,\n",
       "  0.8268181818181819,\n",
       "  0.82625,\n",
       "  0.8279545454545455,\n",
       "  0.8270454545454545,\n",
       "  0.8273863636363636,\n",
       "  0.8276136363636364],\n",
       " 'train_loss': [0.4371206039942584,\n",
       "  0.4185764163153843,\n",
       "  0.41646292487394465,\n",
       "  0.41417044516906,\n",
       "  0.41311233266464714,\n",
       "  0.4147604938270976,\n",
       "  0.4139543606818301,\n",
       "  0.41314644793283595,\n",
       "  0.41301094053439724,\n",
       "  0.41297246602553767],\n",
       " 'val_loss': [0.4150359366427768,\n",
       "  0.41359441727399826,\n",
       "  0.4089807021346959,\n",
       "  0.4097648798064752,\n",
       "  0.41002653539180756,\n",
       "  0.41066586700352753,\n",
       "  0.4089528342539614,\n",
       "  0.4097812033512376,\n",
       "  0.4095045890320431,\n",
       "  0.40940282426097174]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train(model, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
