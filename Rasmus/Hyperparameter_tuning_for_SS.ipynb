{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 4: PREPARE THE PROPOSALS FOR TRAINING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary of procedure:\n",
    "\n",
    "- Iterate through all images and their annotations.\n",
    "\n",
    "- Calculate the IoU for each proposal and assign the corresponding label.\n",
    "\n",
    "- Store the information about proposals and labels in a format useful for training.\n",
    "\n",
    "- Save the prepared data for use in the object detection model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import cv2\n",
    "import selectivesearch\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")  # Go up one level, adjust as necessary\n",
    "\n",
    "from module.utils import  (\n",
    "    parse_xml, \n",
    "    prepare_proposals, \n",
    "    get_proposals, \n",
    "    calculate_iou, \n",
    "    load_image, \n",
    "    get_id,\n",
    "    calc_recall, \n",
    "    calc_abo,\n",
    "    from_xywh_to_min_max)\n",
    "import matplotlib.pyplot as plt\n",
    "import xml.etree.ElementTree as ET\n",
    "import numpy as np\n",
    "# Moving active directory to root folder to get module to work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = \"../Potholes/annotated-images/\"\n",
    "anno_path = \"../Potholes/annotated-images/\"\n",
    "# This does not scale. We should save annotation proposals in a file. \n",
    "\n",
    "image_count = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the above function in a class for generating the Pothole images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# proposal_data, labels = prepare_proposals(img_path, anno_path, 500, 0.5, image_count)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_image(image, boxes, proposals=None, scale_x=1.0, scale_y=1.0):\n",
    "    # Adjust ground truth boxes according to the scale\n",
    "    adjusted_boxes = [(int(xmin * scale_x), int(ymin * scale_y), int(xmax * scale_x), int(ymax * scale_y)) for xmin, ymin, xmax, ymax in boxes]\n",
    "    \n",
    "    # Convert color for display\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Draw ground truth boxes in blue\n",
    "    for (xmin, ymin, xmax, ymax) in adjusted_boxes:\n",
    "        cv2.rectangle(image, (xmin, ymin), (xmax, ymax), (255, 0, 0), 2)\n",
    "    \n",
    "    # Draw Selective Search proposals in green if provided\n",
    "    if proposals is not None:\n",
    "        for (x, y, w, h) in proposals:\n",
    "            x, y, w, h = int(x), int(y), int(w), int(h)\n",
    "\n",
    "            cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 1)\n",
    "            # cv2.putText(image, (15, 15), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "\n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir(img_path)\n",
    "\n",
    "\n",
    "image_paths = np.array(list(filter(lambda file: file.endswith(\".jpg\"), files)))\n",
    "label_paths = np.array(list(filter(lambda file: file.endswith(\".xml\"), files)))\n",
    "\n",
    "\n",
    "boxes = [parse_xml(anno_path + label_path) for label_path in label_paths[:image_count]]\n",
    "images = [load_image(img_path + img) for img in image_paths[:image_count]]\n",
    "\n",
    "\n",
    "# visualize_image(image, boxes=boxes, proposals=proposal_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_WIDTH, TARGET_HEIGHT = 400, 400\n",
    "\n",
    "# Loop through images, resize if needed, and apply Selective Search\n",
    "image_counter = 0\n",
    "\n",
    "# for image, boxs, proposals in zip(images, boxes, proposal_data):\n",
    "    \n",
    "    \n",
    "        \n",
    "#     # Calculate scaling factors\n",
    "#     orig_height, orig_width = image.shape[:2]\n",
    "#     scale_x = orig_width\n",
    "#     scale_y = orig_height\n",
    "\n",
    "#     # Resize the image to improve Selective Search efficiency\n",
    "\n",
    "#     # # Run Selective Search on resized image\n",
    "\n",
    "#     # Convert to integer type before passing the image\n",
    "#     # or simply\n",
    "#     # resized_image_int = resized_image.astype(np.uint8)  # if resized_image is in a valid range of 0-255 but in float\n",
    "\n",
    "#     # Use this converted version in operations\n",
    "\n",
    "#     visualize_image(image, boxs, proposals)  # To Display uncomment\n",
    "\n",
    "#     # Break to only visualize a few images\n",
    "#     image_counter += 1\n",
    "#     if image_counter >= 10:\n",
    "        # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # To change the number of proposals we will vary the scale on the selectivesearch function \n",
    "# # (this is done to not truncate and have a better distribution of the proposals)\n",
    "# # scales = [25, 50, 100, 200, 400, 600, 800, 1000, 2000, 3000]\n",
    "# scales = [1, 5, 10, 20, 40, 60, 80, 100, 200, 300]\n",
    "# sigmas = [0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "# # MAX_IMAGES = 20 # Number of image we will take into account to do the recall\n",
    "\n",
    "# # Keep the recalls in a diccionary\n",
    "# results = {scale: {'num_proposals': 0, 'recall': []} for scale in scales}\n",
    "\n",
    "\n",
    "# # Loop through images to evaluate proposals\n",
    "# image_count = 0\n",
    "# MAX_IMAGES = 20\n",
    "\n",
    "# TARGET_WIDTH = 400\n",
    "# TARGET_HEIGHT = 400\n",
    "# image_paths = np.array(list(filter(lambda file: file.endswith(\".jpg\"), files)))\n",
    "# label_paths = np.array(list(filter(lambda file: file.endswith(\".xml\"), files)))\n",
    "\n",
    "# image_paths = sorted(image_paths, key=get_id)\n",
    "# label_paths = sorted(label_paths, key=get_id)\n",
    "\n",
    "# for img_name, label_name in zip(image_paths, label_paths):\n",
    "#     # Stop processing after reaching the limit of images\n",
    "#     if image_count >= MAX_IMAGES:\n",
    "#         break\n",
    "\n",
    "#     image_path = os.path.join(img_path, img_name)\n",
    "#     xml_path = os.path.join(anno_path, label_name)\n",
    "        \n",
    "#     # Load image and ground truth\n",
    "#     image = cv2.imread(image_path)\n",
    "#     if os.path.exists(xml_path):\n",
    "#         ground_truth_boxes = parse_xml(xml_path)\n",
    "            \n",
    "#         # Dimensions for resizing image \n",
    "#         orig_height, orig_width = image.shape[:2]\n",
    "#         scale_x = orig_width\n",
    "#         scale_y = orig_height\n",
    "            \n",
    "#         # Resize ground truth boxes\n",
    "#         # resized_gt_boxes = [(int(xmin * scale_x), int(ymin * scale_y), int(xmax * scale_x), int(ymax * scale_y)) for xmin, ymin, xmax, ymax in ground_truth_boxes]\n",
    "            \n",
    "#         # Resize image and generate proposals\n",
    "#         resized_image = cv2.resize(image, (TARGET_WIDTH, TARGET_HEIGHT))\n",
    "            \n",
    "\n",
    "#         # Evaluate for each proposal_count\n",
    "#         for scale in scales:\n",
    "#             proposals = get_proposals(resized_image, 5000, scale)\n",
    "#             results[scale]['num_proposals'] += len(proposals)\n",
    "\n",
    "#             # Calculate the recall \n",
    "#             recall = calc_recall(proposals, ground_truth_boxes, iou_threshold=0.5)\n",
    "#             results[scale]['recall'].append(recall)\n",
    "\n",
    "#         image_count += 1\n",
    "#         print (f\"{img_name}:{image_count}, {len(proposals)}\", end=\"\\r\")\n",
    "\n",
    "\n",
    "# # Calculate average recall and the number of proposals for each scale\n",
    "# average_recalls = {scale: np.mean(results[scale]['recall']) for scale in scales}\n",
    "\n",
    "# # Prepare data for plotting\n",
    "# average_num_proposals = {scale: results[scale]['num_proposals'] / image_count for scale in scales} \n",
    "\n",
    "# # Sort the scales based on the average number of proposals\n",
    "# # sorted_scales = sorted(average_num_proposals.keys(), key=lambda scale: average_num_proposals[scale])\n",
    "# # sorted_num_proposals = [average_num_proposals[scale] for scale in sorted_scales]\n",
    "# # sorted_recalls = [average_recalls[scale] for scale in sorted_scales]\n",
    "\n",
    "# # Display the results and the number of proposals per scale\n",
    "# # for scale in scales:\n",
    "# #     avg_props = average_num_proposals[scale]\n",
    "# #     avg_recall = average_recalls[scale]\n",
    "# #     print(f\"Scale: {scale}, Average Proposals: {avg_props:.2f}, Average Recall: {avg_recall:.2f}\")\n",
    "\n",
    "# # Plot the results\n",
    "# plt.figure(figsize=(10, 6))\n",
    "\n",
    "\n",
    "# num_proposals = [results[scale]['num_proposals'] / image_count for scale in scales]\n",
    "# recalls = [average_recalls[scale] for scale in scales]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(scales, recalls, marker='o')\n",
    "\n",
    "\n",
    "# plt.xlabel(\"Scales\")\n",
    "# plt.ylabel(\"Average Recall\")\n",
    "# plt.title(\"Recall vs Number of Proposals with Different Scales\")\n",
    "# plt.grid()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sigma\n",
    "Testing effect of sigma in selective search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # To change the number of proposals we will vary the scale on the selectivesearch function \n",
    "# # (this is done to not truncate and have a better distribution of the proposals)\n",
    "# # scales = [25, 50, 100, 200, 400, 600, 800, 1000, 2000, 3000]\n",
    "# sigmas = [0.1,0.2,0.3,0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "# # MAX_IMAGES = 20 # Number of image we will take into account to do the recall\n",
    "\n",
    "# # Keep the recalls in a diccionary\n",
    "# results = {sigma: {'num_proposals': 0, 'recall': []} for sigma in sigmas}\n",
    "\n",
    "\n",
    "# # Loop through images to evaluate proposals\n",
    "# image_count = 0\n",
    "# MAX_IMAGES = 20\n",
    "\n",
    "# TARGET_WIDTH = 800\n",
    "# TARGET_HEIGHT = 800\n",
    "# image_paths = np.array(list(filter(lambda file: file.endswith(\".jpg\"), files)))\n",
    "# label_paths = np.array(list(filter(lambda file: file.endswith(\".xml\"), files)))\n",
    "\n",
    "# image_paths = sorted(image_paths, key=get_id)\n",
    "# label_paths = sorted(label_paths, key=get_id)\n",
    "\n",
    "# for img_name, label_name in zip(image_paths, label_paths):\n",
    "#     # Stop processing after reaching the limit of images\n",
    "#     if image_count >= MAX_IMAGES:\n",
    "#         break\n",
    "\n",
    "#     image_path = os.path.join(img_path, img_name)\n",
    "#     xml_path = os.path.join(anno_path, label_name)\n",
    "        \n",
    "#     # Load image and ground truth\n",
    "#     image = cv2.imread(image_path)\n",
    "#     if os.path.exists(xml_path):\n",
    "#         ground_truth_boxes = parse_xml(xml_path)\n",
    "            \n",
    "#         # Dimensions for resizing image \n",
    "#         orig_height, orig_width = image.shape[:2]\n",
    "#         scale_x = orig_width\n",
    "#         scale_y = orig_height\n",
    "            \n",
    "#         # Resize ground truth boxes\n",
    "#         # resized_gt_boxes = [(int(xmin * scale_x), int(ymin * scale_y), int(xmax * scale_x), int(ymax * scale_y)) for xmin, ymin, xmax, ymax in ground_truth_boxes]\n",
    "            \n",
    "#         # Resize image and generate proposals\n",
    "#         resized_image = cv2.resize(image, (TARGET_WIDTH, TARGET_HEIGHT))\n",
    "            \n",
    "\n",
    "#         # Evaluate for each proposal_count\n",
    "#         for sigma in sigmas:\n",
    "#             proposals = get_proposals(resized_image, 5000, scale=100, sigma=sigma, min_size=300 )\n",
    "#             results[sigma]['num_proposals'] += len(proposals)\n",
    "\n",
    "#             # Calculate the recall \n",
    "#             recall = calc_recall(proposals, ground_truth_boxes, iou_threshold=0.5)\n",
    "#             results[sigma]['recall'].append(recall)\n",
    "\n",
    "#         image_count += 1\n",
    "#         print (f\"{img_name}:{image_count}, {len(proposals)}\", end=\"\\r\")\n",
    "\n",
    "\n",
    "# # Calculate average recall and the number of proposals for each scale\n",
    "# average_recalls = {sigma: np.mean(results[sigma]['recall']) for sigma in sigmas}\n",
    "\n",
    "# # Prepare data for plotting\n",
    "# average_num_proposals = {sigma: results[sigma]['num_proposals'] / image_count for sigma in sigmas} \n",
    "\n",
    "# # Sort the scales based on the average number of proposals\n",
    "# # sorted_scales = sorted(average_num_proposals.keys(), key=lambda scale: average_num_proposals[scale])\n",
    "# # sorted_num_proposals = [average_num_proposals[scale] for scale in sorted_scales]\n",
    "# # sorted_recalls = [average_recalls[scale] for scale in sorted_scales]\n",
    "\n",
    "# # Display the results and the number of proposals per scale\n",
    "# # for scale in scales:\n",
    "# #     avg_props = average_num_proposals[scale]\n",
    "# #     avg_recall = average_recalls[scale]\n",
    "# #     print(f\"Scale: {scale}, Average Proposals: {avg_props:.2f}, Average Recall: {avg_recall:.2f}\")\n",
    "\n",
    "# # Plot the results\n",
    "# plt.figure(figsize=(10, 6))\n",
    "\n",
    "\n",
    "# num_proposals = [results[sigma]['num_proposals'] / image_count for sigma in sigmas]\n",
    "# recalls = [average_recalls[sigma] for sigma in sigmas]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(sigmas, recalls, marker='o')\n",
    "\n",
    "\n",
    "# plt.xlabel(\"Sigma\")\n",
    "# plt.ylabel(\"Average Recall\")\n",
    "# plt.title(\"Recall value for different sigma\")\n",
    "# plt.grid()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the range of scales and sigmas for hyperparameter tuning\n",
    "# scales = [10, 25, 50, 75, 100]\n",
    "# sigmas = [0.6,0.8,1.0, 1.1,1.2, 1.3]\n",
    "\n",
    "# # Maximum number of images to process\n",
    "# MAX_IMAGES = 5\n",
    "\n",
    "# # Image dimensions\n",
    "# TARGET_WIDTH = 800\n",
    "# TARGET_HEIGHT = 800\n",
    "\n",
    "# # Initialize results dictionary to store metrics for each (scale, sigma) combination\n",
    "# results = {}\n",
    "\n",
    "\n",
    "# files = os.listdir(img_path)\n",
    "\n",
    "# image_paths = np.array([file for file in files if file.endswith(\".jpg\")])\n",
    "# label_paths = np.array([file for file in files if file.endswith(\".xml\")])\n",
    "\n",
    "# # Sort the file lists to ensure correct pairing\n",
    "# image_paths = sorted(image_paths)\n",
    "# label_paths = sorted(label_paths)\n",
    "\n",
    "# # Initialize image counter\n",
    "# image_count = 0\n",
    "\n",
    "# # Loop through images to evaluate proposals\n",
    "# for img_name, label_name in zip(image_paths, label_paths):\n",
    "#     # Stop processing after reaching the limit of images\n",
    "#     if image_count >= MAX_IMAGES:\n",
    "#         break\n",
    "\n",
    "#     image_path = os.path.join(img_path, img_name)\n",
    "#     xml_path = os.path.join(anno_path, label_name)\n",
    "\n",
    "#     # Load image and ground truth\n",
    "#     image = cv2.imread(image_path)\n",
    "#     if image is None:\n",
    "#         continue  # Skip if image failed to load\n",
    "\n",
    "#     if os.path.exists(xml_path):\n",
    "#         ground_truth_boxes = parse_xml(xml_path)  # This function should return a list of boxes in (xmin, ymin, xmax, ymax) format\n",
    "\n",
    "#         # Dimensions for resizing image \n",
    "#         orig_height, orig_width = image.shape[:2]\n",
    "#         scale_x = TARGET_WIDTH / orig_width\n",
    "#         scale_y = TARGET_HEIGHT / orig_height\n",
    "            \n",
    "#         # Resize ground truth boxes\n",
    "#         resized_gt_boxes = [(int(xmin * scale_x), int(ymin * scale_y), int(xmax * scale_x), int(ymax * scale_y)) for xmin, ymin, xmax, ymax in ground_truth_boxes]\n",
    "            \n",
    "        \n",
    "#         # Resize image\n",
    "#         resized_image = cv2.resize(image, (TARGET_WIDTH, TARGET_HEIGHT))\n",
    "\n",
    "#         # Loop over all combinations of scale and sigma\n",
    "#         for scale in scales:\n",
    "#             for sigma in sigmas:\n",
    "#                 key = (scale, sigma)\n",
    "#                 if key not in results:\n",
    "#                     results[key] = {'num_proposals': 0, 'recall': [], 'abo': []}\n",
    "\n",
    "#                 # Generate proposals with current scale and sigma\n",
    "#                 proposals = get_proposals(\n",
    "#                     resized_image,\n",
    "#                     5000,\n",
    "#                     scale=scale,\n",
    "#                     sigma=sigma,\n",
    "#                     min_size=300\n",
    "#                 )\n",
    "\n",
    "#                 results[key]['num_proposals'] += len(proposals)\n",
    "\n",
    "#                 # Calculate the recall\n",
    "#                 recall = calc_recall(proposals, ground_truth_boxes, iou_threshold=0.5)\n",
    "#                 results[key]['recall'].append(recall)\n",
    "\n",
    "#                 # Calculate the ABO\n",
    "#                 abo = calc_abo(proposals, ground_truth_boxes)\n",
    "#                 results[key]['abo'].append(abo)\n",
    "\n",
    "#         image_count += 1\n",
    "#         print(f\"Processed {image_count}/{MAX_IMAGES} images\", end=\"\\r\")\n",
    "#     else:\n",
    "#         continue  # Skip images without annotations\n",
    "\n",
    "# # Calculate average recall, ABO, and the number of proposals for each (scale, sigma) combination\n",
    "# average_recalls = {key: np.mean(results[key]['recall']) for key in results}\n",
    "# average_abos = {key: np.mean(results[key]['abo']) for key in results}\n",
    "# average_num_proposals = {key: results[key]['num_proposals'] / image_count for key in results}\n",
    "\n",
    "\n",
    "# # Prepare data for plotting or analysis\n",
    "# # You can reshape the results into a grid if you want to visualize them as heatmaps\n",
    "\n",
    "# # Example: Print out the results\n",
    "# print(\"\\nScale\\tSigma\\tAvg Proposals\\tAvg Recall\")\n",
    "# print(\"----------------------------------------------\")\n",
    "# for (scale, sigma) in sorted(results.keys()):\n",
    "#     avg_props = average_num_proposals[(scale, sigma)]\n",
    "#     avg_recall = average_recalls[(scale, sigma)]\n",
    "#     print(f\"{scale}\\t{sigma}\\t{avg_props:.2f}\\t\\t{avg_recall:.2f}\")\n",
    "\n",
    "# # If you want to plot recall vs number of proposals for each sigma or scale\n",
    "# # Here's an example for plotting recall vs number of proposals for each sigma at a fixed scale\n",
    "# fixed_scale = 100  # Change this to the scale you want to fix\n",
    "# filtered_keys = [key for key in results if key[0] == fixed_scale]\n",
    "\n",
    "# # Sort the filtered keys based on sigma\n",
    "# filtered_keys.sort(key=lambda x: x[1])\n",
    "\n",
    "# num_proposals = [average_num_proposals[key] for key in filtered_keys]\n",
    "# recalls = [average_recalls[key] for key in filtered_keys]\n",
    "# sigmas_fixed_scale = [key[1] for key in filtered_keys]\n",
    "\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.plot(num_proposals, recalls, marker='o')\n",
    "# plt.xlabel(\"Average Number of Proposals\")\n",
    "# plt.ylabel(\"Average Recall\")\n",
    "# plt.title(f\"Recall vs Number of Proposals at Scale {fixed_scale}\")\n",
    "# plt.xticks(ticks=num_proposals, labels=[f\"{sigma:.1f}\" for sigma in sigmas_fixed_scale])\n",
    "# plt.grid()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['img-1.jpg',\n",
       " 'img-2.jpg',\n",
       " 'img-3.jpg',\n",
       " 'img-4.jpg',\n",
       " 'img-5.jpg',\n",
       " 'img-6.jpg',\n",
       " 'img-7.jpg',\n",
       " 'img-8.jpg',\n",
       " 'img-9.jpg',\n",
       " 'img-10.jpg',\n",
       " 'img-11.jpg',\n",
       " 'img-12.jpg',\n",
       " 'img-13.jpg',\n",
       " 'img-14.jpg',\n",
       " 'img-15.jpg',\n",
       " 'img-16.jpg',\n",
       " 'img-17.jpg',\n",
       " 'img-18.jpg',\n",
       " 'img-19.jpg',\n",
       " 'img-20.jpg']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = os.listdir(img_path)\n",
    "\n",
    "image_paths = np.array([file for file in files if file.endswith(\".jpg\")])\n",
    "label_paths = np.array([file for file in files if file.endswith(\".xml\")])\n",
    "\n",
    "# Sort the file lists to ensure correct pairing\n",
    "image_paths = sorted(image_paths, key=get_id)\n",
    "label_paths = sorted(label_paths, key=get_id)\n",
    "image_paths[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the range of scales and sigmas for hyperparameter tuning\n",
    "# # scales = [5, 10, 20, 25]\n",
    "# # sigmas = [0.6,0.8, 1, 1.2]\n",
    "# scales = [5, 10, 20, 50]\n",
    "# sigmas = [0.6, 0.8,1.0,1.2]\n",
    "# # Maximum number of images to process\n",
    "# MAX_IMAGES = 40\n",
    "# # Image dimensions\n",
    "# TARGET_WIDTH = 600\n",
    "# TARGET_HEIGHT = 600\n",
    "\n",
    "# # Initialize results dictionary to store metrics for each (scale, sigma) combination\n",
    "# results = {}\n",
    "\n",
    "\n",
    "\n",
    "# # # Limit the number of images to process\n",
    "# # if MAX_IMAGES is not None:\n",
    "# #     image_paths = image_paths[:MAX_IMAGES]\n",
    "# #     label_paths = label_paths[:MAX_IMAGES]\n",
    "\n",
    "# # Loop over all combinations of scale and sigma\n",
    "# for scale in scales:\n",
    "#     for sigma in sigmas:\n",
    "#         key = (scale, sigma)\n",
    "#         if key not in results:\n",
    "#             results[key] = {'num_proposals': 0, 'recall': [], 'abo': []}\n",
    "\n",
    "#         # Prepare proposals for the current scale and sigma\n",
    "#         proposal_data, labels = prepare_proposals(\n",
    "#             images_path=img_path,\n",
    "#             annotations_path=anno_path,\n",
    "#             proposals_per_image=500,\n",
    "#             iou_threshold=0.5,\n",
    "#             scale=scale,\n",
    "#             sigma=sigma,\n",
    "#             min_size=60,\n",
    "#             image_shape=(TARGET_HEIGHT, TARGET_WIDTH),\n",
    "#             count=MAX_IMAGES\n",
    "#         )\n",
    "\n",
    "#         num_images = MAX_IMAGES\n",
    "\n",
    "#         # Process each image to calculate recall and ABO\n",
    "#         for i in range(num_images):\n",
    "#             # Get the proposals and labels for this image\n",
    "#             proposals = proposal_data[i]  # Shape: (proposals_per_image, 4)\n",
    "#             #filter proposals which are empty\n",
    "            \n",
    "#             # Proposals are in (x, y, w, h) format\n",
    "\n",
    "#             # Get the corresponding image and annotation filenames\n",
    "#             img_name = os.path.join(img_path, image_paths[i])\n",
    "#             label_name = os.path.join(anno_path, label_paths[i])\n",
    "#             # print(img_name)\n",
    "\n",
    "#             image = load_image(img_name)\n",
    "\n",
    "            \n",
    "#             original_height, original_width = image.shape[:2]\n",
    "#             height_ratio = TARGET_HEIGHT / original_height\n",
    "#             width_ratio = TARGET_WIDTH / original_width\n",
    "#             ground_truth_boxes = parse_xml(label_name)  # Should return boxes in (xmin, ymin, xmax, ymax) format\n",
    "            \n",
    "#             # Resize ground truth boxes\n",
    "#             ground_truth_boxes = [\n",
    "#                 (\n",
    "#                     int(xmin * width_ratio),\n",
    "#                     int(ymin * height_ratio),\n",
    "#                     int(xmax * width_ratio),\n",
    "#                     int(ymax * height_ratio)\n",
    "#                 )\n",
    "#                 for (xmin, ymin, xmax, ymax) in ground_truth_boxes\n",
    "#             ]\n",
    "            \n",
    "#             # Load ground truth boxes\n",
    "\n",
    "#             # No need to resize ground truth boxes; they are already resized in `prepare_proposals`\n",
    "\n",
    "#             num_ground_truth_boxes = len(ground_truth_boxes)\n",
    "            \n",
    "#             # Initialize variables for recall and ABO calculations\n",
    "#             detected_gt_boxes = 0\n",
    "#             best_overlaps = []\n",
    "            \n",
    "#             abo = calc_abo(proposals, ground_truth_boxes)\n",
    "#             recall = calc_recall(proposals, ground_truth_boxes, iou_threshold=0.5)\n",
    "            \n",
    "\n",
    "#             # Update results\n",
    "#             results[key]['recall'].append(recall)\n",
    "#             results[key]['abo'].append(abo)\n",
    "#             results[key]['num_proposals'] += len(proposals)\n",
    "\n",
    "#         print(f\"Processed scale={scale}, sigma={sigma} for {num_images} images, recall={np.mean(results[key]['recall'])}\")\n",
    "\n",
    "# # Calculate average recall, ABO, and the number of proposals for each (scale, sigma) combination\n",
    "# average_recalls = {key: np.mean(results[key]['recall']) for key in results}\n",
    "# average_abos = {key: np.mean(results[key]['abo']) for key in results}\n",
    "# average_num_proposals = {key: results[key]['num_proposals'] / num_images for key in results}\n",
    "\n",
    "# # Example: Print out the results\n",
    "# print(\"\\nScale\\tSigma\\tAvg Proposals\\tAvg Recall\\tAvg ABO\")\n",
    "# print(\"--------------------------------------------------------\")\n",
    "# for (scale, sigma) in sorted(results.keys()):\n",
    "#     avg_props = average_num_proposals[(scale, sigma)]\n",
    "#     avg_recall = average_recalls[(scale, sigma)]\n",
    "#     avg_abo = average_abos[(scale, sigma)]\n",
    "#     print(f\"{scale}\\t{sigma}\\t{avg_props:.2f}\\t\\t{avg_recall:.2f}\\t\\t{avg_abo:.2f}\")\n",
    "\n",
    "# # If you want to plot recall vs number of proposals for each sigma at a fixed scale\n",
    "# fixed_scale = 100  # Change this to the scale you want to fix\n",
    "# filtered_keys = [key for key in results if key[0] == fixed_scale]\n",
    "\n",
    "# # Sort the filtered keys based on sigma\n",
    "# filtered_keys.sort(key=lambda x: x[1])\n",
    "\n",
    "# num_proposals = [average_num_proposals[key] for key in filtered_keys]\n",
    "# recalls = [average_recalls[key] for key in filtered_keys]\n",
    "# sigmas_fixed_scale = [key[1] for key in filtered_keys]\n",
    "\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.plot(num_proposals, recalls, marker='o')\n",
    "# plt.xlabel(\"Average Number of Proposals\")\n",
    "# plt.ylabel(\"Average Recall\")\n",
    "# plt.title(f\"Recall vs Number of Proposals at Scale {fixed_scale}\")\n",
    "# plt.xticks(ticks=num_proposals, labels=[f\"{sigma:.1f}\" for sigma in sigmas_fixed_scale])\n",
    "# plt.grid()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed k=5, sigma=0.6, min_size=200 for 30 images, recall=0.8978\n",
      "Processed k=5, sigma=0.6, min_size=300 for 30 images, recall=0.9711\n",
      "Processed k=5, sigma=0.6, min_size=400 for 30 images, recall=0.9106\n",
      "Processed k=5, sigma=0.6, min_size=500 for 30 images, recall=0.9133\n",
      "Processed k=5, sigma=0.8, min_size=200 for 30 images, recall=0.8883\n",
      "Processed k=5, sigma=0.8, min_size=300 for 30 images, recall=0.9228\n",
      "Processed k=5, sigma=0.8, min_size=400 for 30 images, recall=0.9561\n",
      "Processed k=5, sigma=0.8, min_size=500 for 30 images, recall=0.9183\n",
      "Processed k=10, sigma=0.6, min_size=200 for 30 images, recall=0.9200\n",
      "Processed k=10, sigma=0.6, min_size=300 for 30 images, recall=0.8867\n",
      "Processed k=10, sigma=0.6, min_size=400 for 30 images, recall=0.9428\n",
      "Processed k=10, sigma=0.6, min_size=500 for 30 images, recall=0.9517\n",
      "Processed k=10, sigma=0.8, min_size=200 for 30 images, recall=0.9494\n",
      "Processed k=10, sigma=0.8, min_size=300 for 30 images, recall=0.9517\n",
      "Processed k=10, sigma=0.8, min_size=400 for 30 images, recall=0.9489\n",
      "Processed k=10, sigma=0.8, min_size=500 for 30 images, recall=0.8744\n",
      "Processed k=15, sigma=0.6, min_size=200 for 30 images, recall=0.8933\n",
      "Processed k=15, sigma=0.6, min_size=300 for 30 images, recall=0.9061\n",
      "Processed k=15, sigma=0.6, min_size=400 for 30 images, recall=0.9200\n",
      "Processed k=15, sigma=0.6, min_size=500 for 30 images, recall=0.9494\n",
      "Processed k=15, sigma=0.8, min_size=200 for 30 images, recall=0.9478\n",
      "Processed k=15, sigma=0.8, min_size=300 for 30 images, recall=0.9161\n",
      "Processed k=15, sigma=0.8, min_size=400 for 30 images, recall=0.9117\n",
      "Processed k=15, sigma=0.8, min_size=500 for 30 images, recall=0.9411\n",
      "\n",
      "k\tSigma\tMin_Size\tAvg Proposals\tAvg Recall\tAvg ABO\n",
      "--------------------------------------------------------------\n",
      "5\t0.6\t200\t\t34.73\t\t0.90\t\t0.70\n",
      "5\t0.6\t300\t\t37.13\t\t0.97\t\t0.75\n",
      "5\t0.6\t400\t\t36.13\t\t0.91\t\t0.73\n",
      "5\t0.6\t500\t\t35.07\t\t0.91\t\t0.74\n",
      "5\t0.8\t200\t\t34.63\t\t0.89\t\t0.72\n",
      "5\t0.8\t300\t\t37.37\t\t0.92\t\t0.72\n",
      "5\t0.8\t400\t\t36.53\t\t0.96\t\t0.72\n",
      "5\t0.8\t500\t\t36.23\t\t0.92\t\t0.74\n",
      "10\t0.6\t200\t\t36.47\t\t0.92\t\t0.73\n",
      "10\t0.6\t300\t\t36.40\t\t0.89\t\t0.72\n",
      "10\t0.6\t400\t\t36.27\t\t0.94\t\t0.73\n",
      "10\t0.6\t500\t\t35.27\t\t0.95\t\t0.72\n",
      "10\t0.8\t200\t\t36.27\t\t0.95\t\t0.74\n",
      "10\t0.8\t300\t\t36.10\t\t0.95\t\t0.75\n",
      "10\t0.8\t400\t\t35.83\t\t0.95\t\t0.73\n",
      "10\t0.8\t500\t\t36.60\t\t0.87\t\t0.70\n",
      "15\t0.6\t200\t\t35.50\t\t0.89\t\t0.73\n",
      "15\t0.6\t300\t\t36.40\t\t0.91\t\t0.73\n",
      "15\t0.6\t400\t\t37.30\t\t0.92\t\t0.74\n",
      "15\t0.6\t500\t\t36.53\t\t0.95\t\t0.75\n",
      "15\t0.8\t200\t\t33.83\t\t0.95\t\t0.71\n",
      "15\t0.8\t300\t\t36.17\t\t0.92\t\t0.71\n",
      "15\t0.8\t400\t\t35.63\t\t0.91\t\t0.73\n",
      "15\t0.8\t500\t\t37.43\t\t0.94\t\t0.75\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# Define the range of k (scale), sigmas, and min_sizes for hyperparameter tuning\n",
    "scales = [5,10]\n",
    "sigmas = [0.5,0.6, 0.8]\n",
    "min_sizes = [200,300]  # Add your desired min_size values here\n",
    "\n",
    "# Maximum number of images to process\n",
    "MAX_IMAGES = 30\n",
    "\n",
    "# Image dimensions\n",
    "TARGET_WIDTH = 800\n",
    "TARGET_HEIGHT = 800\n",
    "\n",
    "# Initialize results dictionary to store metrics for each (k, sigma, min_size) combination\n",
    "results = {}\n",
    "\n",
    "# Get image and label paths\n",
    "files = os.listdir(img_path)\n",
    "image_paths = [file for file in files if file.endswith(\".jpg\")]\n",
    "label_paths = [file for file in files if file.endswith(\".xml\")]\n",
    "\n",
    "# Sort the file lists to ensure correct pairing\n",
    "image_paths = sorted(image_paths, key=get_id)\n",
    "label_paths = sorted(label_paths, key=get_id)\n",
    "\n",
    "# Limit the number of images to process\n",
    "if MAX_IMAGES is not None:\n",
    "    image_paths = image_paths[:MAX_IMAGES]\n",
    "    label_paths = label_paths[:MAX_IMAGES]\n",
    "\n",
    "num_images = len(image_paths)\n",
    "\n",
    "# Loop over all combinations of k, sigma, and min_size\n",
    "for scale in scales:\n",
    "    for sigma in sigmas:\n",
    "        for min_size in min_sizes:\n",
    "            key = (scale, sigma, min_size)\n",
    "            if key not in results:\n",
    "                results[key] = {'num_proposals': 0, 'recall': [], 'abo': []}\n",
    "\n",
    "            # Prepare proposals for the current k, sigma, and min_size\n",
    "            proposal_data, labels = prepare_proposals(\n",
    "                images_path=img_path,\n",
    "                annotations_path=anno_path,\n",
    "                proposals_per_image=500,\n",
    "                iou_threshold=0.5,\n",
    "                scale=scale,  # Use 'k' instead of 'scale'\n",
    "                sigma=sigma,\n",
    "                min_size=min_size,\n",
    "                image_shape=(TARGET_HEIGHT, TARGET_WIDTH),\n",
    "                count=MAX_IMAGES\n",
    "            )\n",
    "\n",
    "            # Process each image to calculate recall and ABO\n",
    "            for i in range(num_images):\n",
    "                # Get the proposals and labels for this image\n",
    "                proposals = proposal_data[i]  # List of proposals (x, y, w, h)\n",
    "\n",
    "                # Get the corresponding image and annotation filenames\n",
    "                img_name = os.path.join(img_path, image_paths[i])\n",
    "                label_name = os.path.join(anno_path, label_paths[i])\n",
    "\n",
    "                image = cv2.imread(img_name)\n",
    "\n",
    "                original_height, original_width = image.shape[:2]\n",
    "                height_ratio = TARGET_HEIGHT / original_height\n",
    "                width_ratio = TARGET_WIDTH / original_width\n",
    "\n",
    "                # Load and resize ground truth boxes\n",
    "                ground_truth_boxes = parse_xml(label_name)  # Returns boxes in (xmin, ymin, xmax, ymax) format\n",
    "                ground_truth_boxes = [\n",
    "                    (\n",
    "                        int(xmin * width_ratio),\n",
    "                        int(ymin * height_ratio),\n",
    "                        int(xmax * width_ratio),\n",
    "                        int(ymax * height_ratio)\n",
    "                    )\n",
    "                    for (xmin, ymin, xmax, ymax) in ground_truth_boxes\n",
    "                ]\n",
    "\n",
    "                num_ground_truth_boxes = len(ground_truth_boxes)\n",
    "\n",
    "                # Calculate ABO and recall\n",
    "                abo = calc_abo(proposals, ground_truth_boxes)\n",
    "                recall = calc_recall(proposals, ground_truth_boxes, iou_threshold=0.5)\n",
    "\n",
    "                # Update results\n",
    "                results[key]['recall'].append(recall)\n",
    "                results[key]['abo'].append(abo)\n",
    "                results[key]['num_proposals'] += len(proposals)\n",
    "\n",
    "            avg_recall = np.mean(results[key]['recall'])\n",
    "            print(f\"Processed k={scale}, sigma={sigma}, min_size={min_size} for {num_images} images, recall={avg_recall:.4f}\")\n",
    "\n",
    "# Calculate average recall, ABO, and the number of proposals for each (k, sigma, min_size) combination\n",
    "average_recalls = {key: np.mean(results[key]['recall']) for key in results}\n",
    "average_abos = {key: np.mean(results[key]['abo']) for key in results}\n",
    "average_num_proposals = {key: results[key]['num_proposals'] / num_images for key in results}\n",
    "\n",
    "# Print out the results\n",
    "print(\"\\nk\\tSigma\\tMin_Size\\tAvg Proposals\\tAvg Recall\\tAvg ABO\")\n",
    "print(\"--------------------------------------------------------------\")\n",
    "for (k, sigma, min_size) in sorted(results.keys()):\n",
    "    avg_props = average_num_proposals[(k, sigma, min_size)]\n",
    "    avg_recall = average_recalls[(k, sigma, min_size)]\n",
    "    avg_abo = average_abos[(k, sigma, min_size)]\n",
    "    print(f\"{k}\\t{sigma}\\t{min_size}\\t\\t{avg_props:.2f}\\t\\t{avg_recall:.2f}\\t\\t{avg_abo:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Prepare data for plotting or analysis\n",
    "data = []\n",
    "for (k, sigma, min_size) in results.keys():\n",
    "    avg_props = average_num_proposals[(k, sigma, min_size)]\n",
    "    avg_recall = average_recalls[(k, sigma, min_size)]\n",
    "    avg_abo = average_abos[(k, sigma, min_size)]\n",
    "    data.append({\n",
    "        'Scale (k)': k,\n",
    "        'Sigma': sigma,\n",
    "        'Min_Size': min_size,\n",
    "        'Avg Proposals': avg_props,\n",
    "        'Avg Recall': avg_recall,\n",
    "        'Avg ABO': avg_abo\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Get the list of unique min_size values\n",
    "min_size_values = df['Min_Size'].unique()\n",
    "\n",
    "# Plot heatmaps for each min_size value\n",
    "for min_size in min_size_values:\n",
    "    # Filter the DataFrame for the current min_size\n",
    "    df_min_size = df[df['Min_Size'] == min_size]\n",
    "    \n",
    "    # Pivot the DataFrame to create matrices for heatmaps\n",
    "    recall_pivot = df_min_size.pivot(index='Scale (k)', columns='Sigma', values='Avg Recall')\n",
    "    abo_pivot = df_min_size.pivot(index='Scale (k)', columns='Sigma', values='Avg ABO')\n",
    "    proposals_pivot = df_min_size.pivot(index='Scale (k)', columns='Sigma', values='Avg Proposals')\n",
    "    \n",
    "    # Plot heatmap for Average Recall\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.heatmap(recall_pivot, annot=True, fmt=\".4f\", cmap=\"YlGnBu\")\n",
    "    plt.title(f'Average Recall for Different Scale and Sigma Values\\n(min_size = {min_size})')\n",
    "    plt.xlabel('Sigma')\n",
    "    plt.ylabel('Scale (k)')\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot heatmap for Average ABO\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.heatmap(abo_pivot, annot=True, fmt=\".4f\", cmap=\"YlGnBu\")\n",
    "    plt.title(f'Average ABO for Different Scale and Sigma Values\\n(min_size = {min_size})')\n",
    "    plt.xlabel('Sigma')\n",
    "    plt.ylabel('Scale (k)')\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot heatmap for Average Number of Proposals\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.heatmap(proposals_pivot, annot=True, fmt=\".0f\", cmap=\"YlGnBu\")\n",
    "    plt.title(f'Average Number of Proposals for Different Scale and Sigma Values\\n(min_size = {min_size})')\n",
    "    plt.xlabel('Sigma')\n",
    "    plt.ylabel('Scale (k)')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test-environment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
