{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import cv2\n",
    "import selectivesearch\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")  # Go up one level, adjust as necessary\n",
    "\n",
    "from module.utils import  parse_xml, prepare_proposals,get_proposals, calculate_iou, load_image, get_id,calc_recall, calc_abo, resize_box\n",
    "import matplotlib.pyplot as plt\n",
    "import xml.etree.ElementTree as ET\n",
    "import numpy as np\n",
    "#import torch \n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "img_path = \"../Potholes/annotated-images/\"\n",
    "anno_path = \"../Potholes/annotated-images/\"\n",
    "# This does not scale. We should save annotation proposals in a file. \n",
    "\n",
    "image_count = 1000\n",
    "\n",
    "files = os.listdir(img_path)\n",
    "\n",
    "\n",
    "image_paths = np.array(list(filter(lambda file: file.endswith(\".jpg\"), files)))\n",
    "label_paths = np.array(list(filter(lambda file: file.endswith(\".xml\"), files)))\n",
    "\n",
    "image_paths = sorted(image_paths, key=get_id)\n",
    "label_paths = sorted(label_paths, key=get_id)\n",
    "\n",
    "\n",
    "boxes = [parse_xml(anno_path + label_path) for label_path in label_paths[:image_count]]\n",
    "images = [load_image(img_path + img) for img in image_paths[:image_count]]\n",
    "\n",
    "\n",
    "# IMAGE_WIDTH = 800\n",
    "# IMAGE_HEIGHT = 800\n",
    "\n",
    "# IMAGE_SIZE = (IMAGE_WIDTH,IMAGE_HEIGHT)\n",
    "# boxes = [[resize_box(box, (image.shape[1], image.shape[0]), IMAGE_SIZE) for box in tmp_boxes] for (tmp_boxes,image) in zip(boxes,images)]\n",
    "# images = [cv2.resize(image, IMAGE_SIZE) for image in images]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/665 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 665/665 [03:43<00:00,  2.98it/s]\n"
     ]
    }
   ],
   "source": [
    "proposal_boxes, labels = prepare_proposals(\n",
    "    img_path,\n",
    "    anno_path,\n",
    "    1200, \n",
    "    0.5,\n",
    "    scale=15,\n",
    "    sigma=1.2,\n",
    "    min_size=50,\n",
    "    image_shape=None,\n",
    "    count=image_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_image(image, boxes,labels, proposals=None, scale_x=1.0, scale_y=1.0):\n",
    "    # Adjust ground truth boxes according to the scale\n",
    "    \n",
    "    # Convert color for display\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Draw ground truth boxes in blue\n",
    "    for (xmin, ymin, xmax, ymax) in boxes:\n",
    "        cv2.rectangle(image, (xmin, ymin), (xmax, ymax), (255, 0, 0), 2)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Draw Selective Search proposals in green if provided\n",
    "    if proposals is not None:\n",
    "        for (x, y, w, h), label in zip(proposals,labels):\n",
    "            # Adjust Selective Search boxes according to the scale\n",
    "            x = x * scale_x\n",
    "            y = y * scale_y\n",
    "            w = w * scale_x\n",
    "            h = h * scale_y\n",
    "\n",
    "            x, y, w, h = int(x), int(y), int(w), int(h)\n",
    "            if label == 1:\n",
    "                cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "            # else:\n",
    "            #     cv2.rectangle(image, (x, y), (x + w, y + h), (0, 0, 255), 1)\n",
    "                \n",
    "            # cv2.putText(image, (15, 15), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "\n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25.951"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = 0\n",
    "for li in labels:\n",
    "    for lj in li:\n",
    "        if lj == 1:\n",
    "            count += 1\n",
    "count / image_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_count = 5\n",
    "# for i in range(image_count):\n",
    "#     # Calculate scale_x and scale_y\n",
    "#     # scale_x = images[i].shape[1] \n",
    "#     # scale_y = images[i].shape[0] \n",
    "#     scale_x = 1\n",
    "#     scale_y = 1 \n",
    "\n",
    "\n",
    "#     visualize_image(images[i], boxes[i], labels[i], proposal_boxes[i], scale_x=scale_x, scale_y=scale_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import os\n",
    "\n",
    "def create_xml_from_proposals(image_filename, proposals, output_folder, images_path):\n",
    "    # Create a new XML structure for the proposals\n",
    "    root = ET.Element(\"annotation\")\n",
    "    folder = ET.SubElement(root, \"folder\")\n",
    "    folder.text = \"Proposals\"\n",
    "    \n",
    "    \n",
    "    \n",
    "    filename_elem = ET.SubElement(root, \"filename\")\n",
    "    filename_elem.text = image_filename\n",
    "\n",
    "    size = ET.SubElement(root, \"size\")\n",
    "    width_elem = ET.SubElement(size, \"width\")\n",
    "    height_elem = ET.SubElement(size, \"height\")\n",
    "    depth_elem = ET.SubElement(size, \"depth\")\n",
    "\n",
    "    # Load the image to get its size\n",
    "    image_path = os.path.join(images_path, image_filename)\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        print(f\"Error: Could not load image at {image_path}\")\n",
    "        return\n",
    "    height, width, depth = image.shape\n",
    "\n",
    "    height_elem.text = str(height)\n",
    "    width_elem.text = str(width)\n",
    "    depth_elem.text = str(depth)\n",
    "\n",
    "    # Add the proposals as objects\n",
    "    for idx, proposal in enumerate(proposals):\n",
    "        object_elem = ET.SubElement(root, \"object\")\n",
    "        name = ET.SubElement(object_elem, \"name\")\n",
    "        name.text = \"proposal\"  # You can customize this name if needed\n",
    "\n",
    "        bndbox = ET.SubElement(object_elem, \"bndbox\")\n",
    "        xmin = ET.SubElement(bndbox, \"xmin\")\n",
    "        ymin = ET.SubElement(bndbox, \"ymin\")\n",
    "        xmax = ET.SubElement(bndbox, \"xmax\")\n",
    "        ymax = ET.SubElement(bndbox, \"ymax\")\n",
    "\n",
    "        xmin.text = str(int(proposal[0]))  # x1 coordinate\n",
    "        ymin.text = str(int(proposal[1]))  # y1 coordinate\n",
    "        xmax.text = str(int(proposal[2]))  # x2 coordinate\n",
    "        ymax.text = str(int(proposal[3]))  # y2 coordinate\n",
    "\n",
    "    # Save XML to output folder\n",
    "    output_xml_path = os.path.join(output_folder, image_filename.replace(\".jpg\", \"_proposals.xml\").replace(\".png\", \"_proposals.xml\"))\n",
    "    tree = ET.ElementTree(root)\n",
    "    tree.write(output_xml_path)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# proposal_boxes, labels = prepare_proposals(\n",
    "#     img_path,\n",
    "#     anno_path,\n",
    "#     1200, \n",
    "#     0.5,\n",
    "#     scale=5,\n",
    "#     sigma=0.6,\n",
    "#     min_size=200,\n",
    "#     image_shape=IMAGE_SIZE,\n",
    "#     count=30)\n",
    "\n",
    "\n",
    "output_folder = \"tmp/\"\n",
    "\n",
    "for i in range(len(proposal_boxes)):\n",
    "    image_filename = image_paths[i]\n",
    "    image_id = get_id(image_filename)\n",
    "    assert image_id-1 == i\n",
    "    create_xml_from_proposals(image_filename, proposal_boxes[i], output_folder, img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test-environment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
