{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/zhome/81/e/154648/repos/Object-Detection/Rasmus\n",
      "Average split of proposals (IoU >= 0.5): 0.020719298245614037\n",
      "average recall for (IoU >= 0.5): 0.9339107087152321\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import selectivesearch\n",
    "import sys\n",
    "# print current directory\n",
    "print(os.getcwd())\n",
    "sys.path.append(\"..\")  # Go up one level, adjust as necessary\n",
    "\n",
    "from module.utils import  (\n",
    "    parse_xml, \n",
    "    prepare_proposals, \n",
    "    get_proposals, \n",
    "    calculate_iou, \n",
    "    load_image, \n",
    "    get_id,\n",
    "    calc_recall, \n",
    "    calc_abo,\n",
    "    from_xywh_to_min_max,\n",
    "    visualize_image,\n",
    "    resize_boxes)\n",
    "from module.dataloader import (\n",
    "    PotholeDataset\n",
    ")\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import xml.etree.ElementTree as ET\n",
    "import numpy as np\n",
    "import torch.utils.data as data\n",
    "# Moving active directory to root folder to get module to work\n",
    "\n",
    "img_path = \"../Potholes/annotated-images/\"\n",
    "anno_path = \"../Potholes/annotated-images/\"\n",
    "proposal_path = \"tmp/\"\n",
    "# This does not scale. We should save annotation proposals in a file. \n",
    "\n",
    "IMAGE_WIDTH = 800\n",
    "IMAGE_HEIGHT = 800\n",
    "IMAGE_SIZE = (IMAGE_WIDTH,IMAGE_HEIGHT)\n",
    "\n",
    "\n",
    "img_files = os.listdir(img_path)\n",
    "proposal_files = os.listdir(proposal_path)\n",
    "\n",
    "image_paths = np.array(list(filter(lambda file: file.endswith(\".jpg\"), img_files)))\n",
    "label_paths = np.array(list(filter(lambda file: file.endswith(\".xml\"), img_files)))\n",
    "proposal_paths = np.array(list(filter(lambda file: file.endswith(\".xml\"), proposal_files)))\n",
    "# sort the files\n",
    "image_paths = sorted(image_paths, key=get_id)\n",
    "label_paths = sorted(label_paths, key=get_id)\n",
    "proposal_paths = sorted(proposal_files, key=get_id)\n",
    "\n",
    "# Limit to the first 100 images\n",
    "image_paths = image_paths[:]\n",
    "label_paths = label_paths[:]\n",
    "proposal_paths = proposal_paths[:]\n",
    "\n",
    "boxes = [parse_xml(anno_path + label_path) for label_path in label_paths]\n",
    "images = [load_image(img_path + img) for img in image_paths]\n",
    "proposals = [parse_xml(proposal_path + proposal) for proposal in proposal_paths]\n",
    "gt_boxes = [resize_boxes(boxs, (image.shape[1], image.shape[0]), IMAGE_SIZE) for boxs, image in zip(boxes, images)]\n",
    "\n",
    "# Proposals and gt boxes are in a (xmin,ymin,xmax, ymax) format\n",
    "# We want to calculate the iou for each image using gt and proposals\n",
    "\n",
    "def calculate_average_split(proposals, ground_truth_boxes, iou_threshold=0.5):\n",
    "    total_proposals = 0\n",
    "    overlapping_proposals = 0\n",
    "\n",
    "    for proposal_set, gt_boxes in zip(proposals, ground_truth_boxes):\n",
    "        for proposal in proposal_set:\n",
    "            proposal_box = from_xywh_to_min_max(proposal)\n",
    "            for gt_box in gt_boxes:\n",
    "                iou = calculate_iou(proposal_box, gt_box)\n",
    "                if iou >= iou_threshold:\n",
    "                    overlapping_proposals += 1\n",
    "                    break\n",
    "            total_proposals += 1\n",
    "\n",
    "    average_split = overlapping_proposals / total_proposals if total_proposals > 0 else 0\n",
    "    return average_split\n",
    "\n",
    "def calculate_split_for_each_image(proposals, ground_truth_boxes, iou_threshold=0.5):\n",
    "    splits = []\n",
    "\n",
    "    for proposal_set, gt_boxes in zip(proposals, ground_truth_boxes):\n",
    "        total_proposals = 0\n",
    "        overlapping_proposals = 0\n",
    "        for proposal in proposal_set:\n",
    "            proposal_box = from_xywh_to_min_max(proposal)\n",
    "            for gt_box in gt_boxes:\n",
    "                iou = calculate_iou(proposal_box, gt_box)\n",
    "                if iou >= iou_threshold:\n",
    "                    overlapping_proposals += 1\n",
    "                    break\n",
    "            total_proposals += 1\n",
    "        split = overlapping_proposals / total_proposals if total_proposals > 0 else 0\n",
    "        splits.append(split)\n",
    "\n",
    "    return splits\n",
    "\n",
    "def calculate_recal(proposals, ground_truth_boxes, iou_threshold=0.5):\n",
    "\n",
    "    recall = 0\n",
    "    for proposal_set, gt_boxes in zip(proposals, ground_truth_boxes):\n",
    "        recall += calc_recall(proposal_set, gt_boxes, iou_threshold)\n",
    "\n",
    "    recall = recall / len(proposal_files)\n",
    "    return recall\n",
    "\n",
    "# Calculate the average split for the first 100 images\n",
    "average_split = calculate_average_split(proposals, gt_boxes)\n",
    "print(f\"Average split of proposals (IoU >= 0.5): {average_split}\")\n",
    "\n",
    "average_recall = calculate_recal(proposals, gt_boxes)\n",
    "print(f\"average recall for (IoU >= 0.5): {average_recall}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Calculate the split for each of the first 100 images\n",
    "# splits = calculate_split_for_each_image(proposals, boxes)\n",
    "# for idx, split in enumerate(splits):\n",
    "#     print(f\"Image {idx + 1}: Split of proposals overlapping with gt boxes (IoU >= 0.5): {split}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "potholeDataset = PotholeDataset(img_path, proposal_path, anno_path, image_size=IMAGE_SIZE, iou_threshold=0.5)\n",
    "\n",
    "dataloader = data.DataLoader(potholeDataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 665/665 [00:07<00:00, 91.44it/s] \n"
     ]
    }
   ],
   "source": [
    "# compare np array with torch tensor\n",
    "def compare_np_torch(np_array, torch_tensor):\n",
    "    return np.all(np_array == torch_tensor.numpy())\n",
    "\n",
    "def compare_labels_using_io(proposals, gt_boxes, iou_threshold=0.5):\n",
    "    potholes = 0\n",
    "    for proposal in proposals:\n",
    "        for gt_box in gt_boxes:\n",
    "            iou = calculate_iou(proposal, gt_box)\n",
    "            if iou >= iou_threshold:\n",
    "                potholes += 1\n",
    "                break\n",
    "    return potholes / len(proposals)\n",
    "\n",
    "\n",
    "\n",
    "potholes = 0\n",
    "for i, data in tqdm.tqdm(enumerate(dataloader), total=len(potholeDataset)):\n",
    "    t_image, t_proposals, t_gt = data['image'], data['proposals'], data['gt_boxes']\n",
    "    potholes = compare_labels_using_io(t_proposals[0], t_gt[0], 0.5)\n",
    "potholes = potholes / len(potholeDataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16797007402357858"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test-environment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
