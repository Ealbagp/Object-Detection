{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/zhome/81/e/154648/repos/Object-Detection/Rasmus\n",
      "Average split of proposals (IoU >= 0.5): 0.03260302850990428\n",
      "average recall for (IoU >= 0.5): 0.9478743290379972\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import selectivesearch\n",
    "import sys\n",
    "# print current directory\n",
    "print(os.getcwd())\n",
    "sys.path.append(\"..\")  # Go up one level, adjust as necessary\n",
    "\n",
    "from module.utils import  (\n",
    "    parse_xml, \n",
    "    prepare_proposals, \n",
    "    get_proposals, \n",
    "    calculate_iou, \n",
    "    load_image, \n",
    "    get_id,\n",
    "    calc_recall, \n",
    "    calc_abo,\n",
    "    from_xywh_to_min_max,\n",
    "    visualize_image,\n",
    "    resize_boxes)\n",
    "from module.dataloader import (\n",
    "    PotholeDataset\n",
    ")\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import xml.etree.ElementTree as ET\n",
    "import numpy as np\n",
    "import torch.utils.data as data\n",
    "# Moving active directory to root folder to get module to work\n",
    "\n",
    "img_path = \"../Potholes/annotated-images/\"\n",
    "anno_path = \"../Potholes/annotated-images/\"\n",
    "proposal_path = \"tmp/\"\n",
    "# This does not scale. We should save annotation proposals in a file. \n",
    "\n",
    "# IMAGE_WIDTH = 800\n",
    "# IMAGE_HEIGHT = 800\n",
    "# IMAGE_SIZE = (IMAGE_WIDTH,IMAGE_HEIGHT)\n",
    "\n",
    "\n",
    "img_files = os.listdir(img_path)\n",
    "proposal_files = os.listdir(proposal_path)\n",
    "\n",
    "image_paths = np.array(list(filter(lambda file: file.endswith(\".jpg\"), img_files)))\n",
    "label_paths = np.array(list(filter(lambda file: file.endswith(\".xml\"), img_files)))\n",
    "proposal_paths = np.array(list(filter(lambda file: file.endswith(\".xml\"), proposal_files)))\n",
    "# sort the files\n",
    "image_paths = sorted(image_paths, key=get_id)\n",
    "label_paths = sorted(label_paths, key=get_id)\n",
    "proposal_paths = sorted(proposal_files, key=get_id)\n",
    "\n",
    "image_paths = image_paths[:]\n",
    "label_paths = label_paths[:]\n",
    "proposal_paths = proposal_paths[:]\n",
    "\n",
    "gt_boxes = [parse_xml(anno_path + label_path) for label_path in label_paths]\n",
    "images = [load_image(img_path + img) for img in image_paths]\n",
    "proposals = [parse_xml(proposal_path + proposal) for proposal in proposal_paths]\n",
    "# gt_boxes = [resize_boxes(boxs, (image.shape[1], image.shape[0]), IMAGE_SIZE) for boxs, image in zip(boxes, images)]\n",
    "\n",
    "# Proposals and gt boxes are in a (xmin,ymin,xmax, ymax) format\n",
    "# We want to calculate the iou for each image using gt and proposals\n",
    "\n",
    "def calculate_average_split(proposals, ground_truth_boxes, iou_threshold=0.5):\n",
    "    total_proposals = 0\n",
    "    overlapping_proposals = 0\n",
    "\n",
    "    for proposal_set, gt_boxes in zip(proposals, ground_truth_boxes):\n",
    "        for proposal in proposal_set:\n",
    "            proposal_box = from_xywh_to_min_max(proposal)\n",
    "            for gt_box in gt_boxes:\n",
    "                iou = calculate_iou(proposal_box, gt_box)\n",
    "                if iou >= iou_threshold:\n",
    "                    overlapping_proposals += 1\n",
    "                    break\n",
    "            total_proposals += 1\n",
    "\n",
    "    average_split = overlapping_proposals / total_proposals if total_proposals > 0 else 0\n",
    "    return average_split\n",
    "\n",
    "def calculate_split_for_each_image(proposals, ground_truth_boxes, iou_threshold=0.5):\n",
    "    splits = []\n",
    "\n",
    "    for proposal_set, gt_boxes in zip(proposals, ground_truth_boxes):\n",
    "        total_proposals = 0\n",
    "        overlapping_proposals = 0\n",
    "        for proposal in proposal_set:\n",
    "            proposal_box = from_xywh_to_min_max(proposal)\n",
    "            for gt_box in gt_boxes:\n",
    "                iou = calculate_iou(proposal_box, gt_box)\n",
    "                if iou >= iou_threshold:\n",
    "                    overlapping_proposals += 1\n",
    "                    break\n",
    "            total_proposals += 1\n",
    "        split = overlapping_proposals / total_proposals if total_proposals > 0 else 0\n",
    "        splits.append(split)\n",
    "\n",
    "    return splits\n",
    "\n",
    "def calculate_recal(proposals, ground_truth_boxes, iou_threshold=0.5):\n",
    "\n",
    "    recall = 0\n",
    "    for proposal_set, gt_boxes in zip(proposals, ground_truth_boxes):\n",
    "        recall += calc_recall(proposal_set, gt_boxes, iou_threshold)\n",
    "\n",
    "    recall = recall / len(proposal_files)\n",
    "    return recall\n",
    "\n",
    "# Calculate the average split for the first 100 images\n",
    "average_split = calculate_average_split(proposals, gt_boxes)\n",
    "print(f\"Average split of proposals (IoU >= 0.5): {average_split}\")\n",
    "\n",
    "average_recall = calculate_recal(proposals, gt_boxes)\n",
    "print(f\"average recall for (IoU >= 0.5): {average_recall}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Calculate the split for each of the first 100 images\n",
    "# splits = calculate_split_for_each_image(proposals, boxes)\n",
    "# for idx, split in enumerate(splits):\n",
    "#     print(f\"Image {idx + 1}: Split of proposals overlapping with gt boxes (IoU >= 0.5): {split}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test = PotholeDataset(\n",
    "    '../Potholes/annotated-images/',\n",
    "    '../Potholes/labeled_proposals/',\n",
    "    '../Potholes/annotated-images/',\n",
    "    transform=None,\n",
    "    proposals_per_batch=50,\n",
    "    proposal_size=(128,128),\n",
    "    balance=0.5,\n",
    "    split='test'\n",
    ")\n",
    "dataloader = data.DataLoader(dataset_test, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test for the dataloader\n",
    "There have been problems with calculate_iou resulting in a "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # compare np array with torch tensor\n",
    "# def compare_np_torch(np_array, torch_tensor):\n",
    "#     return np.all(np_array == torch_tensor.numpy())\n",
    "\n",
    "# def compare_labels_using_io(proposals, gt_boxes, iou_threshold=0.5):\n",
    "#     potholes = 0\n",
    "#     for proposal in proposals:\n",
    "#         for gt_box in gt_boxes:\n",
    "#             try:\n",
    "#                 prop = from_xywh_to_min_max(proposal)\n",
    "                \n",
    "#                 iou = calculate_iou(prop, gt_box)\n",
    "#                 if iou >= iou_threshold:\n",
    "#                     potholes += 1\n",
    "#                     break\n",
    "#             except Exception as e:\n",
    "#                 print(proposal, gt_box)\n",
    "                \n",
    "#     return potholes\n",
    "\n",
    "\n",
    "\n",
    "# potholes = 0\n",
    "# approximate_recall = 0\n",
    "# for _ in range(2):\n",
    "#     for i, data in tqdm.tqdm(enumerate(dataloader), total=len(potholeDataset)):\n",
    "#         t_image, t_proposals, t_gt = data['image'], data['proposals'], data['gt_boxes']\n",
    "#         potholes += compare_labels_using_io(t_proposals[0], t_gt[0], 0.5)\n",
    "#         approximate_recall += calc_recall(t_proposals[0], t_gt[0], 0.5)\n",
    "        \n",
    "# potholes = potholes / len(potholeDataset) / 2\n",
    "# approximate_recall = approximate_recall / len(potholeDataset) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(potholes)\n",
    "# print(approximate_recall)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "iter = iter(dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1)\n",
      "tensor(1)\n",
      "tensor(1)\n",
      "tensor(1)\n",
      "tensor(1)\n",
      "tensor(1)\n",
      "tensor(1)\n",
      "tensor(1)\n",
      "tensor(1)\n",
      "tensor(1)\n",
      "tensor(1)\n",
      "tensor(1)\n",
      "tensor(1)\n",
      "tensor(1)\n",
      "tensor(1)\n",
      "tensor(1)\n",
      "tensor(1)\n",
      "tensor(1)\n",
      "tensor(1)\n",
      "tensor(1)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Get one batch of data\n",
    "\n",
    "\n",
    "img = next(iter)  # Assuming this is a list of proposals\n",
    "proposal_images = img['proposal_images'][0]\n",
    "labels = img['labels'][0]\n",
    "\n",
    "# Plot all proposal images\n",
    "for j in range(min(len(proposal_images), 20)):\n",
    "    # Convert each proposal image to numpy\n",
    "    proposal_image = proposal_images[j].permute(1, 2, 0).numpy().astype(np.uint8)\n",
    "    label = labels[j]\n",
    "    print(label)\n",
    "    # plt.figure(figsize=(5, 5))\n",
    "    # plt.imshow(proposal_image)\n",
    "    # plt.title(f\"Proposal {j}\")\n",
    "    # plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test-environment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
